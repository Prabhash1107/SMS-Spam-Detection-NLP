{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp446wolVNPen4fuW6NQNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prabhash1107/SMS-Spam-Detection-NLP/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "E8YfoT2PawQS",
        "outputId": "25e604e6-bd7d-42d8-cf18-863766af50e4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f8dd30bbac66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-f8dd30bbac66>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_relative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f8dd30bbac66>\u001b[0m in \u001b[0;36mload_model_relative\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the LSTM model with relative path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_relative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dense_Spam_Detection.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model file not found at {model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load the LSTM model with relative path\n",
        "def load_model_relative():\n",
        "    model_path = os.path.join(os.path.dirname(__file__), 'Dense_Spam_Detection.h5')\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Model file not found at {model_path}\")\n",
        "        return None\n",
        "    return load_model(model_path)\n",
        "\n",
        "# Define the function to preprocess the user's input message\n",
        "def preprocess_message(message):\n",
        "    # Convert the message to lowercase\n",
        "    message = message.lower()\n",
        "    # Tokenize the message\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts([message])\n",
        "    # Convert the message to a sequence of integers\n",
        "    sequence = tokenizer.texts_to_sequences([message])\n",
        "    # Pad the sequence with zeros so that it has the same length as the sequences used to train the model\n",
        "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=50)\n",
        "    return padded_sequence\n",
        "\n",
        "# Main function to interact with the user\n",
        "def main():\n",
        "    # Load the model\n",
        "    model = load_model_relative()\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    print(\"Spam Detector\")\n",
        "    print(\"----------------\")\n",
        "\n",
        "    # Ask the user to input a message\n",
        "    message = input(\"Enter a message: \")\n",
        "\n",
        "    # Preprocess the message and make a prediction\n",
        "    if message:\n",
        "        processed_message = preprocess_message(message)\n",
        "        prediction = model.predict(processed_message)\n",
        "\n",
        "        # Display the prediction\n",
        "        if prediction > 0.5:\n",
        "            print(f\"This message is spam with a probability of {prediction[0][0] * 100:.2f}%.\")\n",
        "        else:\n",
        "            print(f\"This message is ham with a probability of {(1 - prediction[0][0]) * 100:.2f}%.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load the LSTM model with relative path\n",
        "def load_model_relative():\n",
        "    # Assuming the model is in the same directory as the notebook\n",
        "    model_path = 'Dense_Spam_Detection.h5'\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Model file not found at {model_path}\")\n",
        "        return None\n",
        "    return load_model(model_path)\n",
        "\n",
        "# Define the function to preprocess the user's input message\n",
        "def preprocess_message(message):\n",
        "    # Convert the message to lowercase\n",
        "    message = message.lower()\n",
        "    # Tokenize the message\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts([message])\n",
        "    # Convert the message to a sequence of integers\n",
        "    sequence = tokenizer.texts_to_sequences([message])\n",
        "    # Pad the sequence with zeros so that it has the same length as the sequences used to train the model\n",
        "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=50)\n",
        "    return padded_sequence\n",
        "\n",
        "# Main function to interact with the user\n",
        "def main():\n",
        "    # Load the model\n",
        "    model = load_model_relative()\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    print(\"Spam Detector\")\n",
        "    print(\"----------------\")\n",
        "\n",
        "    # Ask the user to input a message\n",
        "    message = input(\"Enter a message: \")\n",
        "\n",
        "    # Preprocess the message and make a prediction\n",
        "    if message:\n",
        "        processed_message = preprocess_message(message)\n",
        "        prediction = model.predict(processed_message)\n",
        "\n",
        "        # Display the prediction\n",
        "        if prediction > 0.5:\n",
        "            print(f\"This message is spam with a probability of {prediction[0][0] * 100:.2f}%.\")\n",
        "        else:\n",
        "            print(f\"This message is ham with a probability of {(1 - prediction[0][0]) * 100:.2f}%.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD0MPaK9b6Ca",
        "outputId": "94b6de13-0779-4c97-f351-d17583733923"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file not found at Dense_Spam_Detection.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rvxB93U6cBq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}